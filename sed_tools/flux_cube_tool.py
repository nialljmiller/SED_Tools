#!/usr/bin/env python3
"""Utility helpers for working with precomputed flux cubes.

This module exposes a small command line tool that can

* read the ``flux_cube.bin`` files generated by ``precompute_flux_cube.py``
* evaluate the spectral energy distribution (SED) at arbitrary
  combinations of (teff, logg, metallicity) using cubic Hermite
  interpolation in each axis
* compute bolometric fluxes / magnitudes
* fold SEDs through user supplied filter transmission curves
* interactively select filter systems and compute AB or Vega magnitudes
* create quick-look plots for the interpolated SED (and filters)

The binary format that :func:`precompute_flux_cube` writes is::

    int32 nt, nl, nm, nw
    float64[nt] teff_grid
    float64[nl] logg_grid
    float64[nm] meta_grid
    float64[nw] wavelengths
    float64[nt * nl * nm * nw] flux values stored with the trailing
        dimensions ordered as (teff, logg, metallicity, wavelength)

Example usage from the command line::

    python flux_cube_tool.py --flux-cube data/stellar_models/MODEL/flux_cube.bin

When run interactively the tool reminds you of the valid parameter ranges,
prompts for any missing values, auto-discovers filter curves under
``data/filters/`` (or directories provided via ``--filters``), computes
synthetic photometry for each, and saves a diagnostic plot to ``plots/``.
Optional flags such as ``--plot`` and ``--save-sed`` allow overriding the
output locations or exporting the interpolated spectrum to disk.
"""

from __future__ import annotations

import argparse
import math
import os
import re
import struct
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Sequence, Tuple

FILTER_EXTENSIONS = {".dat", ".txt", ".csv"}

PC_TO_M = 3.085677581e16
RSUN_TO_M = 6.957e8
SPEED_OF_LIGHT_ANG_PER_S = 2.99792458e18  # speed of light in Angstrom/s
AB_ZERO_FLUX = 3.631e-20  # 3631 Jy expressed in erg s^-1 cm^-2 Hz^-1
UNIT_TO_ANGSTROM: Dict[str, float] = {
    "angstrom": 1.0,
    "ang": 1.0,
    "a": 1.0,
    "aa": 1.0,
    "nanometer": 10.0,
    "nanometre": 10.0,
    "nm": 10.0,
    "micrometer": 1.0e4,
    "micrometre": 1.0e4,
    "micron": 1.0e4,
    "um": 1.0e4,
    "millimeter": 1.0e7,
    "millimetre": 1.0e7,
    "mm": 1.0e7,
    "meter": 1.0e10,
    "metre": 1.0e10,
    "m": 1.0e10,
}
VEGA_ZP_KEYS = [
    "zp_vega",
    "vega_zp",
    "vega_flux",
    "zero_point_flux_vega",
    "zero_point_flux",
    "zeropointflux",
    "zeropoint_flux",
    "zeropointflux_ergcm2sa",
    "zeropointflux_ergcm2sang",
    "zeropointfluxergcm2sa",
]


@dataclass
class FilterCurve:
    name: str
    wavelength: np.ndarray
    transmission: np.ndarray
    metadata: Dict[str, object]
    wavelength_unit: str = "angstrom"


@dataclass
class Spectrum:
    wavelength: np.ndarray
    flux: np.ndarray
    metadata: Dict[str, object]
    wavelength_unit: str = "angstrom"


def normalize_metadata_key(key: str) -> str:
    normalized = re.sub(r"[^a-z0-9]+", "_", key.strip().lower())
    return normalized.strip("_")


def parse_metadata_value(value: str) -> object:
    value = value.strip()
    if not value:
        return ""
    try:
        return float(value)
    except ValueError:
        return value


def infer_unit_from_values(values: np.ndarray) -> str:
    if values.size == 0:
        return "angstrom"
    max_value = float(np.max(values))
    if max_value >= 5e4:
        return "angstrom"
    if max_value >= 50:
        return "nanometer"
    if max_value >= 0.5:
        return "micrometer"
    return "meter"


def standardize_wavelength_array(
    values: Sequence[float], unit_hint: str | None = None
) -> Tuple[np.ndarray, np.ndarray, str]:
    arr = np.asarray(values, dtype=float)
    if arr.size == 0:
        raise ValueError("No wavelength data found in file")
    order = np.argsort(arr)
    arr = arr[order]
    unit_key = (unit_hint or "").strip().lower()
    if not unit_key:
        unit_key = infer_unit_from_values(arr)
    factor = UNIT_TO_ANGSTROM.get(unit_key, 1.0)
    converted = arr * factor
    return converted, order, unit_key or "angstrom"


def load_two_column_file(path: str) -> Tuple[List[float], List[float], Dict[str, object]]:
    x_values: List[float] = []
    y_values: List[float] = []
    metadata: Dict[str, object] = {}

    with open(path, "r", encoding="utf-8") as fh:
        for line_no, raw_line in enumerate(fh, start=1):
            line = raw_line.strip()
            if not line:
                continue
            if line.startswith("#"):
                meta = line[1:].strip()
                for sep in (":", "="):
                    if sep in meta:
                        key, value = meta.split(sep, 1)
                        metadata[normalize_metadata_key(key)] = parse_metadata_value(value)
                        break
                else:
                    comments = metadata.setdefault("comments", [])
                    comments.append(meta)
                continue

            normalized = line.replace(",", " ")
            parts = normalized.split()
            if len(parts) < 2:
                continue
            try:
                x = float(parts[0])
                y = float(parts[1])
            except ValueError:
                continue
            x_values.append(x)
            y_values.append(y)

    return x_values, y_values, metadata


def get_metadata_float(metadata: Dict[str, object], keys: Sequence[str]) -> float | None:
    for key in keys:
        if key not in metadata:
            continue
        value = metadata[key]
        if isinstance(value, (int, float)):
            return float(value)
        if isinstance(value, str):
            try:
                return float(value)
            except ValueError:
                continue
    return None

try:
    import matplotlib.pyplot as plt
except Exception:  # pragma: no cover - optional dependency for plotting
    plt = None
import numpy as np


@dataclass
class FluxCube:
    """In-memory representation of a pre-computed flux cube."""

    teff_grid: np.ndarray
    logg_grid: np.ndarray
    meta_grid: np.ndarray
    wavelengths: np.ndarray
    flux: np.ndarray  # shape (nt, nl, nm, nw)

    @classmethod
    def from_file(cls, path: str) -> "FluxCube":
        """Load a :class:`FluxCube` from a binary file."""

        leftover = b""

        with open(path, "rb") as fh:
            header = fh.read(16)
            if len(header) != 16:
                raise ValueError("Flux cube header truncated")
            nt, nl, nm, nw = struct.unpack("4i", header)
            teff = np.fromfile(fh, dtype=np.float64, count=nt)
            logg = np.fromfile(fh, dtype=np.float64, count=nl)
            meta = np.fromfile(fh, dtype=np.float64, count=nm)
            wavelengths = np.fromfile(fh, dtype=np.float64, count=nw)
            flux_expected = nt * nl * nm * nw
            flux_flat = np.fromfile(fh, dtype=np.float64, count=flux_expected)

            if flux_flat.size == flux_expected:
                leftover = fh.read(1)
            else:
                leftover = b""

        if flux_flat.size != flux_expected:
            raise ValueError(
                f"Flux cube body truncated: expected {flux_expected} values,"
                f" found {flux_flat.size}"
            )

        if leftover:
            print("Warning: trailing data detected in flux cube; ignoring extra bytes.")

        # Flux cubes are written in native C-order with shape
        # (nt, nl, nm, nw), so a direct reshape recovers the original
        # axis ordering used during generation.
        flux = flux_flat.reshape((nt, nl, nm, nw))

        return cls(teff, logg, meta, wavelengths, flux)

    # ------------------------------------------------------------------
    # Interpolation helpers

    def _hermite_interp_axis(
        self, values: np.ndarray, grid: np.ndarray, x: float, axis: int
    ) -> np.ndarray:
        """Perform cubic Hermite interpolation along one axis."""

        if values.shape[axis] < 2 or len(grid) < 2:
            # Degenerate axis: return the lone slice without interpolation.
            return np.take(values, 0, axis=axis)

        if not (grid[0] <= x <= grid[-1]):
            raise ValueError(
                f"Requested value {x} is outside interpolation range"
                f" [{grid[0]}, {grid[-1]}]"
            )

        idx = int(np.searchsorted(grid, x) - 1)
        idx = max(0, min(idx, len(grid) - 2))

        x0 = grid[idx]
        x1 = grid[idx + 1]
        h = x1 - x0
        t = (x - x0) / h if h != 0 else 0.0

        f0 = np.take(values, idx, axis=axis)
        f1 = np.take(values, idx + 1, axis=axis)

        m0 = self._axis_derivative(values, grid, idx, axis)
        m1 = self._axis_derivative(values, grid, idx + 1, axis)

        h00 = (2 * t**3) - (3 * t**2) + 1
        h10 = (t**3) - (2 * t**2) + t
        h01 = (-2 * t**3) + (3 * t**2)
        h11 = (t**3) - (t**2)

        return h00 * f0 + h10 * h * m0 + h01 * f1 + h11 * h * m1

    def _axis_derivative(
        self, values: np.ndarray, grid: np.ndarray, idx: int, axis: int
    ) -> np.ndarray:
        n = len(grid)

        if idx <= 0:
            f0 = np.take(values, 0, axis=axis)
            f1 = np.take(values, 1, axis=axis)
            return (f1 - f0) / (grid[1] - grid[0])
        if idx >= n - 1:
            f0 = np.take(values, n - 2, axis=axis)
            f1 = np.take(values, n - 1, axis=axis)
            return (f1 - f0) / (grid[n - 1] - grid[n - 2])

        f_prev = np.take(values, idx - 1, axis=axis)
        f_next = np.take(values, idx + 1, axis=axis)
        x_prev = grid[idx - 1]
        x_next = grid[idx + 1]
        return (f_next - f_prev) / (x_next - x_prev)

    # ------------------------------------------------------------------

    def interpolate_spectrum(self, teff: float, logg: float, meta: float) -> Tuple[np.ndarray, np.ndarray]:
        """Return ``(wavelength, flux)`` at the requested parameter point."""

        tmp = self._hermite_interp_axis(self.flux, self.teff_grid, teff, axis=0)
        tmp = self._hermite_interp_axis(tmp, self.logg_grid, logg, axis=0)
        flux = self._hermite_interp_axis(tmp, self.meta_grid, meta, axis=0)
        return self.wavelengths.copy(), flux


def integrate_flux(wavelength: np.ndarray, flux: np.ndarray) -> float:
    """Compute bolometric flux via trapezoidal integration."""

    return float(np.trapezoid(flux, wavelength))


def bolometric_magnitude(
    wavelength: np.ndarray,
    flux: np.ndarray,
    reference_flux: float = 1.0,
    reference_magnitude: float = 0.0,
) -> Tuple[float, float]:
    """Return bolometric flux and magnitude."""

    fbol = integrate_flux(wavelength, flux)
    if fbol <= 0:
        mag = math.inf
    else:
        mag = reference_magnitude - 2.5 * math.log10(fbol / reference_flux)
    return fbol, mag


def load_filter_curve(path: str, name: str | None = None) -> FilterCurve:
    """Load a filter throughput curve along with its metadata."""

    raw_wavelengths, raw_transmission, metadata = load_two_column_file(path)
    wavelength, order, unit_key = standardize_wavelength_array(
        raw_wavelengths, metadata.get("wavelength_unit") or metadata.get("wavelengthunit")
    )
    transmission = np.asarray(raw_transmission, dtype=float)[order]

    metadata["wavelength_unit_inferred"] = unit_key or "angstrom"
    metadata["wavelength_unit_resolved"] = "angstrom"
    curve_name = name or Path(path).stem
    return FilterCurve(curve_name, wavelength, transmission, metadata, wavelength_unit="angstrom")


def band_average_flux_lambda_from_arrays(
    wavelength: np.ndarray, flux: np.ndarray, transmission: np.ndarray
) -> float:
    numerator = np.trapezoid(flux * transmission, wavelength)
    denom = np.trapezoid(transmission, wavelength)
    if denom == 0:
        raise ValueError("Filter transmission integrates to zero")
    return float(numerator / denom)


def band_average_flux_lambda(
    sed_wavelength: np.ndarray, sed_flux: np.ndarray, curve: FilterCurve
) -> float:
    interp_flux = np.interp(curve.wavelength, sed_wavelength, sed_flux, left=0.0, right=0.0)
    return band_average_flux_lambda_from_arrays(curve.wavelength, interp_flux, curve.transmission)


def band_average_flux_nu(
    sed_wavelength: np.ndarray, sed_flux: np.ndarray, curve: FilterCurve
) -> float:
    interp_flux = np.interp(curve.wavelength, sed_wavelength, sed_flux, left=0.0, right=0.0)
    numerator = np.trapezoid(interp_flux * curve.transmission, curve.wavelength)
    denom = np.trapezoid(
        curve.transmission * SPEED_OF_LIGHT_ANG_PER_S / (curve.wavelength**2), curve.wavelength
    )
    if denom == 0:
        raise ValueError("Filter transmission integrates to zero")
    return float(numerator / denom)


def prompt_scale_choice() -> bool:
    resp = input("\nScale flux for distance (apparent magnitudes)? [y/N]: ").strip().lower()
    return resp in ("y", "yes")

def prompt_distance_m() -> float:
    val = input("Enter distance (append unit 'pc' or 'm', e.g. '10 pc' or '3.1e17 m'): ").strip()
    parts = val.split()
    d = float(parts[0])
    unit = parts[1].lower() if len(parts) > 1 else "pc"
    return d * PC_TO_M if unit == "pc" else d

def prompt_radius_m() -> float:
    val = input("Enter stellar radius (append unit 'Rsun' or 'm', e.g. '1 Rsun' or '7e8 m'): ").strip()
    parts = val.split()
    r = float(parts[0])
    unit = parts[1].lower() if len(parts) > 1 else "Rsun"
    return r * RSUN_TO_M if unit in ("rsun", "r☉", "r_sun") else r


def plot_sed(
    wavelength: np.ndarray,
    flux: np.ndarray,
    filters: Dict[str, FilterCurve] | None = None,
    out_path: str | None = None,
    *,
    xlim: tuple[float, float] | None = None,   # manual override
    clip: str = "auto",                        # "auto" | "flux" | "filters" | "none"
    rel_cutoff: float = 1e-4,                  # keep λ where flux > rel_cutoff * peak
    margin_frac: float = 0.03,                 # pad the chosen window by this fraction
) -> None:
    """Plot the interpolated SED and optional filter curves, with sane x-limits."""

    if plt is None:
        raise ImportError("matplotlib is required for plotting SEDs")

    plt.figure(figsize=(10, 6))
    plt.plot(wavelength, flux, label="Interpolated SED", color="C0")

    peak = np.nanmax(flux) if flux.size else 1.0

    if filters:
        for name, curve in filters.items():
            if curve.transmission.size == 0:
                continue
            scale = np.max(curve.transmission)
            scaled = curve.transmission / scale * peak if scale and scale > 0 else curve.transmission
            plt.plot(curve.wavelength, scaled, label=f"Filter {name}")

    # ---- x-limit logic ----
    if xlim is None and clip != "none":
        candidates: list[tuple[float, float]] = []

        if clip in ("auto", "flux") and flux.size:
            mask = np.isfinite(flux) & (flux > rel_cutoff * peak)
            if np.any(mask):
                wl_lo = np.nanmin(wavelength[mask])
                wl_hi = np.nanmax(wavelength[mask])
                candidates.append((wl_lo, wl_hi))

        if clip in ("auto", "filters") and filters:
            f_los = [np.min(fc.wavelength) for fc in filters.values() if fc.wavelength.size]
            f_his = [np.max(fc.wavelength) for fc in filters.values() if fc.wavelength.size]
            if f_los and f_his:
                candidates.append((min(f_los), max(f_his)))

        if candidates:
            lo = min(c[0] for c in candidates)
            hi = max(c[1] for c in candidates)
            span = hi - lo if hi > lo else 1.0
            lo -= span * margin_frac
            hi += span * margin_frac
            plt.xlim(lo, hi)

    if xlim is not None:
        plt.xlim(*xlim)

    plt.xlabel("Wavelength")
    plt.ylabel("Flux")
    plt.title("Interpolated Spectral Energy Distribution")
    plt.legend()
    plt.grid(True, alpha=0.3)

    if out_path:
        ensure_dir(os.path.dirname(out_path) or ".")
        plt.savefig(out_path, dpi=150)
    else:
        plt.show()
    plt.close()



def ensure_dir(path: str) -> None:
    if path:
        os.makedirs(path, exist_ok=True)


def save_sed(path: str, wavelength: np.ndarray, flux: np.ndarray) -> None:
    ensure_dir(os.path.dirname(path) or ".")
    data = np.column_stack((wavelength, flux))
    header = "wavelength flux"
    np.savetxt(path, data, header=header)


def prompt_for_parameter(name: str, units: str, grid: np.ndarray, provided: float | None) -> float:
    """Return the requested parameter, prompting if ``provided`` is ``None``."""

    if provided is not None:
        return provided

    lower = float(np.min(grid))
    upper = float(np.max(grid))
    prompt = f"Enter target {name} in {units} (range: {lower:g}–{upper:g} {units}): "

    while True:
        try:
            value_str = input(prompt).strip()
        except EOFError:
            raise SystemExit(f"Missing {name}; aborting.")

        try:
            value = float(value_str)
        except ValueError:
            print(f"Could not parse '{value_str}'. Please enter a numeric value.")
            continue

        if not (lower <= value <= upper):
            print(f"Value {value} is outside the supported range {lower:g}–{upper:g} {units}.")
            continue

        return value


def infer_filter_directories(flux_cube_path: str) -> List[Path]:
    """Return likely filter directories based on the flux cube location."""

    cube_path = Path(flux_cube_path).expanduser().resolve()
    candidates: List[Path] = []
    for parent in [cube_path.parent, *cube_path.parents]:
        candidate = parent / "filters"
        if candidate.is_dir():
            candidates.append(candidate)
    return candidates


def collect_filter_files(
    entries: Sequence[str] | None, flux_cube_path: str
) -> Tuple[List[Tuple[str, Path]], List[Path]]:
    """Discover filter files from explicit paths or inferred directories."""

    discovered: List[Path] = []
    search_roots: List[Path] = []

    def add_file(file_path: Path) -> None:
        if file_path.suffix.lower() in FILTER_EXTENSIONS and file_path.is_file():
            discovered.append(file_path)

    if entries:
        for item in entries:
            path = Path(item).expanduser().resolve()
            if path.is_dir():
                search_roots.append(path)
                for file_path in sorted(path.rglob("*")):
                    add_file(file_path)
            elif path.is_file():
                add_file(path)
            else:
                raise FileNotFoundError(f"Filter path '{item}' does not exist")
    else:
        for directory in infer_filter_directories(flux_cube_path):
            search_roots.append(directory)
            for file_path in sorted(directory.rglob("*")):
                add_file(file_path)

    unique_files = list(dict.fromkeys(discovered))
    if not unique_files:
        unique_roots: List[Path] = []
        seen_roots: set[Path] = set()
        for root in search_roots:
            resolved_root = root.resolve()
            if resolved_root not in seen_roots:
                unique_roots.append(resolved_root)
                seen_roots.add(resolved_root)
        return [], unique_roots

    if not search_roots:
        common_root = Path(os.path.commonpath([str(p.parent) for p in unique_files])).resolve()
        search_roots = [common_root]

    unique_roots: List[Path] = []
    seen_roots: set[Path] = set()
    for root in search_roots:
        resolved_root = root.resolve()
        if resolved_root not in seen_roots:
            unique_roots.append(resolved_root)
            seen_roots.add(resolved_root)
    search_roots = unique_roots

    filter_entries: List[Tuple[str, Path]] = []
    existing_names: set[str] = set()
    name_counts: Dict[str, int] = {}

    for file_path in unique_files:
        name: str | None = None
        for root in search_roots:
            try:
                rel = file_path.relative_to(root)
            except ValueError:
                continue
            else:
                name = rel.with_suffix("").as_posix()
                break

        if name is None:
            name = file_path.stem

        base_name = name
        counter = name_counts.get(base_name, 0)
        while name in existing_names:
            counter += 1
            name = f"{base_name}_{counter}"
        name_counts[base_name] = counter

        filter_entries.append((name, file_path))
        existing_names.add(name)

    return filter_entries, search_roots


def extract_filter_system(filter_name: str) -> str:
    if "/" in filter_name:
        return filter_name.split("/", 1)[0]
    if "\\" in filter_name:
        return filter_name.split("\\", 1)[0]
    return filter_name


def prompt_for_filter_system(
    filter_entries: Sequence[Tuple[str, Path]], provided: str | None
) -> Tuple[str | None, Sequence[Tuple[str, Path]]]:
    systems: Dict[str, List[Tuple[str, Path]]] = {}
    for name, path in filter_entries:
        system = extract_filter_system(name)
        systems.setdefault(system, []).append((name, path))

    if provided:
        provided_key = provided.strip()
        if provided_key.lower() in {"all", "*"}:
            return None, filter_entries
        if provided_key in systems:
            return provided_key, systems[provided_key]
        raise SystemExit(
            f"Unknown filter system '{provided}'. Available systems: {', '.join(sorted(systems))}"
        )

    if len(systems) <= 1:
        key = next(iter(systems)) if systems else None
        return key, filter_entries

    print("\nDiscovered filter systems:")
    ordered = sorted((system, len(entries)) for system, entries in systems.items())
    for idx, (system, count) in enumerate(ordered, start=1):
        print(f"  {idx}) {system} ({count} filters)")
    print("  0) All systems")

    while True:
        response = input("Select a filter system by number (or '0' for all): ").strip()
        if not response:
            response = "0"
        if response.lower() in {"all", "a", "*"}:
            return None, filter_entries
        if response == "0":
            return None, filter_entries
        if response.isdigit():
            index = int(response)
            if 1 <= index <= len(ordered):
                system = ordered[index - 1][0]
                return system, systems[system]
        print("Please enter a valid selection from the list above.")


def prompt_for_photometric_system(provided: str | None) -> str:
    if provided:
        normalized = provided.strip().lower()
        if normalized in {"ab", "vega"}:
            return "AB" if normalized == "ab" else "Vega"
        raise SystemExit("Photometric system must be either 'AB' or 'Vega'.")

    while True:
        response = input("Compute magnitudes in the AB or Vega system? [AB/Vega]: ").strip()
        if not response:
            return "AB"
        normalized = response.lower()
        if normalized in {"ab", "a"}:
            return "AB"
        if normalized in {"vega", "v"}:
            return "Vega"
        print("Please answer 'AB' or 'Vega'.")


def discover_vega_candidates(search_roots: Sequence[Path]) -> List[Path]:
    candidates: List[Path] = []
    for root in search_roots:
        if not root.exists():
            continue
        try:
            root = root.resolve()
        except FileNotFoundError:
            continue
        for suffix in (".dat", ".txt", ".csv", ".sed"):
            try:
                for path in root.rglob(f"*vega*{suffix}"):
                    if path.is_file():
                        candidates.append(path)
            except OSError:
                continue
    unique: List[Path] = []
    seen: set[Path] = set()
    for path in candidates:
        resolved = path.resolve()
        if resolved not in seen:
            unique.append(resolved)
            seen.add(resolved)
    return unique


def resolve_vega_spectrum_path(
    provided: str | None, flux_cube_path: Path, hints: Iterable[str | os.PathLike[str]] = ()
) -> Path:
    hint_paths = [Path(hint).expanduser() for hint in hints]
    env_hint = os.environ.get("SED_VEGA_SPECTRUM")
    if env_hint:
        hint_paths.append(Path(env_hint).expanduser())

    if provided:
        candidate = Path(provided).expanduser()
        if candidate.is_file():
            return candidate.resolve()
        raise FileNotFoundError(f"Vega spectrum '{provided}' does not exist")

    for hint in hint_paths:
        if hint.is_file() and "vega" in hint.name.lower():
            return hint.resolve()

    cube_dir = flux_cube_path.parent
    search_roots = [cube_dir, cube_dir.parent, Path.cwd(), Path.cwd() / "data"]
    for hint in hint_paths:
        if hint.is_dir():
            search_roots.append(hint)
        elif hint.is_file():
            search_roots.append(hint.parent)

    candidates = discover_vega_candidates(search_roots)
    if not candidates:
        raise FileNotFoundError("Could not locate a Vega reference spectrum.")
    if len(candidates) == 1:
        return candidates[0]

    print("\nDiscovered potential Vega spectra:")
    for idx, path in enumerate(candidates, start=1):
        print(f"  {idx}) {path}")

    while True:
        choice = input("Select Vega spectrum by number: ").strip()
        if choice.isdigit():
            index = int(choice)
            if 1 <= index <= len(candidates):
                return candidates[index - 1]
        print("Please select one of the listed Vega spectra.")


def load_spectrum(path: str) -> Spectrum:
    wavelengths, fluxes, metadata = load_two_column_file(path)
    wavelength, order, unit_key = standardize_wavelength_array(
        wavelengths, metadata.get("wavelength_unit") or metadata.get("wavelengthunit")
    )
    flux = np.asarray(fluxes, dtype=float)[order]
    metadata["wavelength_unit_inferred"] = unit_key or "angstrom"
    metadata["wavelength_unit_resolved"] = "angstrom"
    return Spectrum(wavelength, flux, metadata, wavelength_unit="angstrom")


def discover_flux_cube_files(hints: Sequence[str | os.PathLike[str]] | None = None) -> List[Path]:
    """Discover ``flux_cube.bin`` files from common locations and hints."""

    hints = list(hints or [])
    env_path = os.environ.get("SED_FLUX_CUBE")
    env_dir = os.environ.get("SED_FLUX_CUBE_DIR")
    if env_path:
        hints.append(env_path)
    if env_dir:
        hints.append(env_dir)

    search_dirs: List[Path] = []
    direct_files: List[Path] = []

    def add_file(path: Path) -> None:
        try:
            resolved = path.expanduser().resolve()
        except FileNotFoundError:
            return
        if resolved.is_file():
            direct_files.append(resolved)

    for hint in hints:
        path = Path(hint).expanduser()
        if path.is_file():
            add_file(path)
        elif path.is_dir():
            search_dirs.append(path)

    this_dir = Path(__file__).resolve().parent
    default_roots = [
        Path.cwd(),
        Path.cwd() / "data",
        Path.cwd() / "data" / "stellar_models",
        this_dir,
        this_dir / "data",
        this_dir / "data" / "stellar_models",
    ]

    for root in default_roots:
        if root not in search_dirs:
            search_dirs.append(root)

    seen: set[Path] = set()
    results: List[Path] = []

    def register(path: Path) -> None:
        try:
            resolved = path.expanduser().resolve()
        except FileNotFoundError:
            return
        if resolved in seen:
            return
        if resolved.is_file():
            seen.add(resolved)
            results.append(resolved)

    for file_path in direct_files:
        register(file_path)

    for directory in search_dirs:
        try:
            directory = directory.expanduser().resolve()
        except FileNotFoundError:
            continue
        if not directory.exists():
            continue
        if directory.is_file():
            register(directory)
            continue
        try:
            for match in directory.rglob("flux_cube.bin"):
                if match.is_file():
                    register(match)
        except OSError:
            continue

    results.sort()
    return results


def resolve_flux_cube_path(path: str) -> Path:
    """Return a concrete flux cube file path.

    Users sometimes provide a directory (e.g. the model root) instead of the
    actual ``flux_cube.bin`` path. Accept either and try to locate the cube in a
    user-friendly way while surfacing actionable errors otherwise.
    """

    candidate = Path(path).expanduser()
    if candidate.is_file():
        return candidate

    if candidate.is_dir():
        matches = sorted(p for p in candidate.rglob("flux_cube.bin") if p.is_file())
        if not matches:
            raise FileNotFoundError(
                f"No flux_cube.bin found under directory '{candidate}'. "
                "Provide a directory containing the cube or the explicit file path."
            )
        if len(matches) > 1:
            formatted = "\n  ".join(str(m) for m in matches[:10])
            more = "\n  ..." if len(matches) > 10 else ""
            raise FileNotFoundError(
                "Multiple flux_cube.bin files found; please specify one explicitly:\n  "
                f"{formatted}{more}"
            )
        return matches[0]

    raise FileNotFoundError(f"Flux cube path '{path}' does not exist")


def prompt_for_flux_cube_path(hints: Sequence[str | os.PathLike[str]] | None = None) -> Path:
    """Interactively determine which flux cube file to use."""

    hints = list(hints or [])

    while True:
        candidates = discover_flux_cube_files(hints)
        if len(candidates) == 1:
            chosen = candidates[0]
            print(f"Using flux cube: {chosen}")
            return chosen
        if len(candidates) > 1:
            print("Discovered flux cube files:")
            for idx, candidate in enumerate(candidates, start=1):
                print(f"  {idx}. {candidate}")
            response = input(
                "Select a flux cube by number or enter a path (or 'q' to quit): "
            ).strip()
            if not response:
                continue
            if response.lower() in {"q", "quit", "exit"}:
                raise SystemExit("No flux cube selected; aborting.")
            if response.isdigit():
                index = int(response)
                if 1 <= index <= len(candidates):
                    return candidates[index - 1]
                print("Invalid selection. Please choose one of the listed numbers.")
                continue
            try:
                return resolve_flux_cube_path(response)
            except FileNotFoundError as exc:
                print(exc)
                continue

        response = input("Enter path to flux_cube.bin (or 'q' to quit): ").strip()
        if not response:
            print("Please provide a path to a flux cube file.")
            continue
        if response.lower() in {"q", "quit", "exit"}:
            raise SystemExit("No flux cube selected; aborting.")
        try:
            return resolve_flux_cube_path(response)
        except FileNotFoundError as exc:
            print(exc)
            hints.append(response)


def main(argv: Sequence[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description="Inspect and interpolate a flux cube")
    parser.add_argument("--flux-cube", help="Path to flux_cube.bin")
    parser.add_argument("--model-dir", help="Model directory containing a flux cube", default=None)
    parser.add_argument("--teff", type=float, help="Target effective temperature (K)")
    parser.add_argument("--logg", type=float, help="Target log g (dex)")
    parser.add_argument("--metallicity", type=float, help="Target metallicity [M/H] (dex)")
    parser.add_argument("--bolometric-reference-flux", type=float, default=1.0,
                        help="Reference flux for bolometric magnitude (default: 1)")
    parser.add_argument("--bolometric-reference-mag", type=float, default=0.0,
                        help="Reference magnitude for bolometric magnitude (default: 0)")
    parser.add_argument("--filters", nargs="*", help="Filter files or directories (all filters discovered are used)")
    parser.add_argument("--filter-system", help="Restrict photometry to a specific filter system")
    parser.add_argument("--photometric-system", choices=["AB", "Vega", "ab", "vega"],
                        help="Photometric system for synthetic magnitudes")
    parser.add_argument("--vega-sed", help="Path to a Vega reference spectrum (required for Vega magnitudes if no zeropoint metadata is provided)")
    parser.add_argument("--plot", help="Write a diagnostic plot to this path (defaults to plots/)")
    parser.add_argument("--save-sed", help="Write interpolated SED (wavelength, flux) to a text file")

    args = parser.parse_args(argv)

    hints: List[str | os.PathLike[str]] = []
    if args.model_dir:
        hints.append(args.model_dir)

    if args.flux_cube:
        flux_cube_path = resolve_flux_cube_path(args.flux_cube)
    else:
        flux_cube_path = prompt_for_flux_cube_path(hints)

    cube = FluxCube.from_file(str(flux_cube_path))

    teff = prompt_for_parameter("effective temperature", "K", cube.teff_grid, args.teff)
    logg = prompt_for_parameter("surface gravity (log g)", "dex", cube.logg_grid, args.logg)
    metallicity = prompt_for_parameter("metallicity [M/H]", "dex", cube.meta_grid, args.metallicity)

    wl, flux = cube.interpolate_spectrum(teff, logg, metallicity)

    # >>> NEW: optional apparent-flux scaling <<<
    if prompt_scale_choice():
        d_m = prompt_distance_m()
        r_m = prompt_radius_m()
        scale = (r_m / d_m) ** 2
        flux = flux * scale
        print(f"[scaling] Applied geometric dilution: (R/d)^2 = {scale:.3e}")

    # Existing code below uses the scaled flux automatically
    fbol, mbol = bolometric_magnitude(
        wl, flux,
        reference_flux=args.bolometric_reference_flux,
        reference_magnitude=args.bolometric_reference_mag,
    )


    print(f"Interpolated SED at Teff={teff}, logg={logg}, [M/H]={metallicity}")
    print(f"Bolometric flux: {fbol:.6e}")
    if math.isfinite(mbol):
        print(f"Bolometric magnitude: {mbol:.4f}")
    else:
        print("Bolometric magnitude: undefined (non-positive flux)")

    filters: Dict[str, FilterCurve] = {}
    filter_entries, filter_roots = collect_filter_files(args.filters, str(flux_cube_path))
    if filter_entries:
        system_name, selected_entries = prompt_for_filter_system(filter_entries, args.filter_system)
        photometric_system = prompt_for_photometric_system(args.photometric_system)

        vega_spec: Spectrum | None = None

        def ensure_vega_spec() -> Spectrum:
            nonlocal vega_spec
            if vega_spec is None:
                try:
                    spectrum_path = resolve_vega_spectrum_path(
                        args.vega_sed, flux_cube_path, args.filters or []
                    )
                except FileNotFoundError as exc:
                    raise SystemExit(
                        f"{exc} Provide a Vega spectrum via --vega-sed or place one near the flux cube."
                    )
                print(f"Using Vega spectrum: {spectrum_path}")
                vega_spec = load_spectrum(str(spectrum_path))
            return vega_spec

        if args.filters:
            source_msg = ", ".join(str(path) for path in filter_roots) if filter_roots else "provided paths"
        else:
            source_msg = ", ".join(str(path) for path in filter_roots) or "inferred filter directories"

        if system_name:
            source_msg = f"{source_msg} (system: {system_name})"

        print(
            f"\nFilter photometry (using {len(selected_entries)} filters from {source_msg})\n"
            f"Photometric system: {photometric_system}"
        )

        for name, fpath in selected_entries:
            curve = load_filter_curve(str(fpath), name)
            filters[name] = curve

            try:
                if photometric_system == "AB":
                    flux_density = band_average_flux_nu(wl, flux, curve)
                    if flux_density <= 0:
                        magnitude = math.inf
                    else:
                        magnitude = -2.5 * math.log10(flux_density / AB_ZERO_FLUX)
                    flux_label = "f_nu"
                else:
                    flux_density = band_average_flux_lambda(wl, flux, curve)
                    vega_zero = get_metadata_float(curve.metadata, VEGA_ZP_KEYS)
                    if vega_zero is None:
                        vega_curve = ensure_vega_spec()
                        interp_flux = np.interp(
                            curve.wavelength,
                            vega_curve.wavelength,
                            vega_curve.flux,
                            left=0.0,
                            right=0.0,
                        )
                        vega_zero = band_average_flux_lambda_from_arrays(
                            curve.wavelength, interp_flux, curve.transmission
                        )
                    if vega_zero <= 0:
                        raise ValueError(
                            "Computed Vega zero point is non-positive; cannot determine magnitude."
                        )
                    magnitude = -2.5 * math.log10(flux_density / vega_zero)
                    flux_label = "f_lambda"
            except ValueError as exc:
                print(f"  {name:30s}  error: {exc}")
                continue

            if math.isfinite(magnitude):
                print(f"  {name:30s}  {flux_label}={flux_density:.6e}  mag={magnitude:.4f}")
            else:
                print(f"  {name:30s}  {flux_label}={flux_density:.6e}  mag=undefined")
    else:
        print("\nNo filter files found; skipping filter photometry.")

    if args.save_sed:
        save_sed(args.save_sed, wl, flux)
        print(f"Saved SED to {args.save_sed}")

    if args.plot:
        plot_path = args.plot
    else:
        plot_filename = f"sed_T{teff:.0f}_g{logg:.2f}_M{metallicity:.2f}.png"
        plot_path = os.path.join("plots", plot_filename)

    plot_sed(wl, flux, filters, out_path=plot_path)
    print(f"Saved plot to {plot_path}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())

